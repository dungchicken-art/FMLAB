{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài toán phân loại sử dụng SVM \n",
    "\n",
    "Mục tiêu: \n",
    "\n",
    "- Xây dựng được mô hình svm sử dụng thư viện sklearn. \n",
    "- Ứng dụng, hiểu cách áp dụng mô hình svm vào giải quyết bài toán thực tế (vd: phân loại văn bản) \n",
    "- Sử dụng độ đo Accuracy để làm độ đo đánh giá chất lượng mô hình. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dữ liệu từ thư mục đã crappy từ trước \n",
    "\n",
    "Cấu trúc thư mục như sau \n",
    "\n",
    "- data/news_1135/\n",
    "\n",
    "    - Kinh tế: \n",
    "        - bài báo 1.txt \n",
    "        - bài báo 2.txt \n",
    "    - Pháp luật\n",
    "        - bài báo 3.txt \n",
    "        - bài báo 4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/news_1135/Tin khác/0218e1df21ce358b9c6485176a48f1fcaeedef67.txt'\n",
      " 'data/news_1135/Khoa học - Công nghệ/bf9889f5f2ffd6c92fa877d35ef0ef5f34f0666d.txt'\n",
      " 'data/news_1135/Tin khác/d74aab054ffe9f8661df13bc52b438b48a63fe48.txt'\n",
      " ...\n",
      " 'data/news_1135/Thời sự/a06c1ec4c146d3b4eb5070a1967e10e5e21bdc5b.txt'\n",
      " 'data/news_1135/Sức khỏe/4187c4a1d528fd9ea4630d2709229df0b0d09c3d.txt'\n",
      " 'data/news_1135/Thể thao/7adaf0c561796f2411340150f18417543ad4403c.txt']\n",
      "\n",
      "Tong so file: 1135\n"
     ]
    }
   ],
   "source": [
    "data_train = load_files(container_path=\"data/news_1135/\", encoding=\"utf-8\")\n",
    "\n",
    "print(data_train.filenames)\n",
    "print()\n",
    "\n",
    "print(\"Tong so file: {}\" .format( len(data_train.filenames)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tiền xử lý dữ liệu đưa dữ liệu từ dạng text về dạng ma trận \n",
    "\n",
    "- Thử nghiệm để kiểm tra hoạt động chuyển hoá dữ liệu về dạng ma trận "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh', 'anh_ấy']\n",
      "10 từ đầu tiên trong từ điển:\n",
      "1 :  ('dân_trí', 6928)\n",
      "2 :  ('sở', 17869)\n",
      "3 :  ('gd', 7729)\n",
      "4 :  ('đt', 23214)\n",
      "5 :  ('tỉnh', 20851)\n",
      "6 :  ('gia_lai', 7816)\n",
      "7 :  ('văn_bản', 21779)\n",
      "8 :  ('2258', 858)\n",
      "9 :  ('sgdđt', 17039)\n",
      "10 :  ('vp', 21572)\n",
      "11 :  ('chấn_chỉnh', 4971)\n"
     ]
    }
   ],
   "source": [
    "# load dữ liệu các stopwords \n",
    "with open(\"data/vietnamese-stopwords.txt\", encoding=\"utf-8\") as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords] \n",
    "print(stopwords[:10])\n",
    "\n",
    "# \n",
    "# Transforming data \n",
    "# Chuyển hoá dữ liệu text về dạng vector tfidf \n",
    "#     - loại bỏ từ dừng\n",
    "#     - sinh từ điển\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords)\n",
    "\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ])\n",
    "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận \n",
    "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array \n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "# print(module_count_vector.vocabulary_)\n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "print(\"10 từ đầu tiên trong từ điển:\")\n",
    "i = 0\n",
    "for k,v in module_count_vector.vocabulary_.items():\n",
    "    i+=1\n",
    "    print(i, \": \", (k, v))\n",
    "    if i > 10:\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 1: sử dụng TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  ('dân_trí', 6928)\n",
      "2 :  ('sở', 17869)\n",
      "3 :  ('gd', 7729)\n",
      "4 :  ('đt', 23214)\n",
      "5 :  ('tỉnh', 20851)\n",
      "6 :  ('gia_lai', 7816)\n",
      "7 :  ('văn_bản', 21779)\n",
      "8 :  ('2258', 858)\n",
      "9 :  ('sgdđt', 17039)\n",
      "10 :  ('vp', 21572)\n",
      "11 :  ('chấn_chỉnh', 4971)\n"
     ]
    }
   ],
   "source": [
    "# Giải\n",
    "# sử dụng TfidfVectorizer\n",
    "tfidf_vector = TfidfVectorizer(stop_words=stopwords)\n",
    "data_preprocessed2 = tfidf_vector.fit_transform(data_train.data, data_train.target)\n",
    "i = 0\n",
    "for k,v in tfidf_vector.vocabulary_.items():\n",
    "    i+=1\n",
    "    print(i, \": \", (k, v))\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sách' 'học_sinh' 'tuyệt_đối']\n"
     ]
    }
   ],
   "source": [
    "# top 3 từ trong văn bản đầu tiên có tfidf cao nhất\n",
    "feature_array = np.array(tfidf_vector.get_feature_names())\n",
    "tfidf_sorting = np.argsort(data_preprocessed2[0].toarray()).flatten()[::-1]\n",
    "\n",
    "n = 3\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "print(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chia dữ liệu làm 2 phần training và testing \n",
    "\n",
    "- Training chiếm 80 % dữ liệu \n",
    "- Testing chiếm 20 % dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu training =  (908, 24389) (908,)\n",
      "Dữ liệu testing =  (227, 24389) (227,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "test_size = 0.2\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split( data_preprocessed, data_train.target, test_size=test_size)\n",
    "\n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training svm model \n",
    "\n",
    "Sử dụng thư viện sklearn để xây dựng mô hình \n",
    "- `svm.SVC(kernel='linear', C=1.0)`: chọn hàm nhân phân tách là linear, tham số C=1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training ...\n",
      "- Train size = (908, 24389)\n",
      "- model - train complete\n"
     ]
    }
   ],
   "source": [
    "print(\"- Training ...\")\n",
    "print(\"- Train size = {}\".format(X_train.shape))\n",
    "model = svm.SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"- model - train complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing svm model \n",
    "\n",
    "Thực hiện dự đoán nhãn cho từng văn bản trong tập test \n",
    "\n",
    "Độ đo đánh giá: \n",
    "> accuracy = tổng số văn bản dự đoán đúng  / tổng số văn bản có trong tập test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Testing ...\n",
      "- Acc = 0.8986784140969163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"- Testing ...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 4: Dự đoán nhãn của văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Công phượng ghi_bàn cho đội_tuyển Việt_nam']\n",
      "  (0, 24149)\t0.4617859604824952\n",
      "  (0, 21498)\t0.23577234678310735\n",
      "  (0, 15553)\t0.6394232142292748\n",
      "  (0, 7777)\t0.4617859604824952\n",
      "  (0, 5847)\t0.33023750089838017\n",
      "label  [5] - Thể thao\n"
     ]
    }
   ],
   "source": [
    "# Tiền xử lý dữ liệu sử dụng module model_rf_preprocess. \n",
    "new_doc = \"Công phượng ghi bàn cho đội tuyển Việt nam\"\n",
    "# Trước hết, cần thực hiện tách từ sử dụng pyvi\n",
    "tokenized_new_doc = ViTokenizer.tokenize(new_doc)\n",
    "# Cần đưa văn bản ở dạng mảng/vector\n",
    "tokenized_new_doc = [tokenized_new_doc]\n",
    "print(tokenized_new_doc)\n",
    "# Rồi sử dụng module model_rf_preprocess\n",
    "input_data_preprocessed = model_rf_preprocess.transform(tokenized_new_doc)\n",
    "print(input_data_preprocessed)\n",
    "\n",
    "label = model.predict(input_data_preprocessed)\n",
    "print('label ', label, '-', data_train.target_names[label[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bài tập bổ sung: \n",
    "\n",
    "### 4.1 Thử nghiệm các tham số \n",
    "\n",
    "- Các tham số với giá trị khác nhau có thể ảnh hưởng để kết quả học \n",
    "- Cần thử nghiệm kỹ lượng để đưa ra kết quả khách quan: tham số C, gamma, kernel. \n",
    "    - Chọn mô hình với bộ tham số cho kết quả tốt nhất \n",
    "- Gợi ý: \n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "    - Sử dụng grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 4: Vẽ Learning curve khảo sát Acc của SVM-linear với tham số C thay đổi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hàm sinh id màu  \n",
    "def get_cmap(n):\n",
    "    return 'C' + str(n)\n",
    "\n",
    "# Hàm thực hiện training model, crossvalidate và vẽ lên đồ thị sử dụng mat libplot \n",
    "def plot_learning_curve(estimator, title, label_curve, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5), new_plot=False,\n",
    "                        idx_color=0):\n",
    "    \n",
    "    # Khởi tạo bức ảnh mới với thư viện plot lib \n",
    "    if new_plot:\n",
    "        # plt.figure()\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Training examples\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.grid()\n",
    "    \n",
    "    # chú thích nếu có \n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "        \n",
    "    # thực hiện training model, ghi nhận các giá trị trong quá trình training \n",
    "    # cv = số fold cross validate, số phần bộ dữ liệu được chia để thực hiện training testing.\n",
    "    # train_sizes = mảng tỉ lệ, các tỉ lệ được hệ thống chọn làm điểm dừng để thực hiện 1 testing \n",
    "    #  train_sizes = [0.3, 0.5] => hệ thống lấy 30 % dữ liệu để train và thực hiện test, tương tự 50 % ..\n",
    "    # scoring = hàm mục tiêu để đánh giá chất lượng mô hình và vẽ lên đồ thị \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=\"accuracy\")\n",
    "    \n",
    "    # Lấy trung bình cộng các giá trị output của các fold \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    # random 1 màu để vẽ \n",
    "    color = get_cmap(idx_color)\n",
    "    \n",
    "    # thực hiện vẽ các giá trị số lên đồ thị với màu vừa được random \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=color)\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=color,\n",
    "             label=label_curve)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_C = [0.001, 0.01, 0.1, 1, 5.0, 10.0, 100]\n",
    "# model title \n",
    "title = \"Learning Curves SVM, Linear kernel, change C\"\n",
    "\n",
    "# duyệt qua mảng các giá trị của tham số C \n",
    "for i, C in enumerate(list_C):\n",
    "    # Với từng giá trị C nhận được, \n",
    "    # thực hiện build model và training cross-validate \n",
    "    # vẽ kết quả tìm được lên đồ thị đường. \n",
    "    text_clf = Pipeline([ \n",
    "                         ('clf', svm.SVC(kernel='linear', C=C)), # mô hình svm với tham số C \n",
    "                         ])\n",
    "    \n",
    "    plt = plot_learning_curve(text_clf, title, \"C = %f\" % (C),\n",
    "                              data_preprocessed, data_train.target,\n",
    "                              (0.0, 1.01), cv=10, n_jobs=-1, idx_color=i, new_plot=i == 0)\n",
    "\n",
    "# lưu hình ảnh ra file \n",
    "# plt.savefig('images/changeC.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 5: Sử dụng GridSearchCV để tìm bộ tham số tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=0.1)\n",
      "Testing\n",
      "0.8502202643171806\n"
     ]
    }
   ],
   "source": [
    "params_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "          'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "          'kernel':['linear','rbf', 'poly'] }\n",
    "\n",
    "model = svm.SVC()\n",
    "#Create the GridSearchCV object\n",
    "best_model = GridSearchCV(model, params_grid, cv=4, n_jobs=-1, scoring = \"accuracy\")\n",
    "\n",
    "#Fit the data with the best possible parameters\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "#Print the best estimator with it's parameters\n",
    "print (best_model.best_params_)\n",
    "print (best_model.best_estimator_)\n",
    "# Test best_model\n",
    "print('Testing')\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Phân loại số viết tay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu training =  (1437, 64) (1437,)\n",
      "Dữ liệu testing =  (360, 64) (360,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 4 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "target = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, target, test_size=test_size)\n",
    "\n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=0.001)\n",
      "Testing\n",
      "0.9805555555555555\n"
     ]
    }
   ],
   "source": [
    "params_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "          'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "          'kernel':['linear','rbf', 'poly'] }\n",
    "\n",
    "model = svm.SVC()\n",
    "#Create the GridSearchCV object\n",
    "best_model = GridSearchCV(model, params_grid, cv=4, n_jobs=-1, scoring = \"accuracy\")\n",
    "\n",
    "#Fit the data with the best possible parameters\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "#Print the best estimator with it's parameters\n",
    "print (best_model.best_params_)\n",
    "print (best_model.best_estimator_)\n",
    "# Test best_model\n",
    "print('Testing')\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}